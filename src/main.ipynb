{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddd0531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re\n",
    "from torchvision.models import EfficientNet_B4_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b425c95b",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9723fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(f):\n",
    "    match = re.search(r'\\d+', f)\n",
    "    return int(match.group()) if match else float('inf')\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted( os.listdir(root_dir), key=extract_number)\n",
    "            #[f for f in os.listdir(root_dir) if f.endswith(('.jpg', '.jpeg', '.png'))],\n",
    "            #key=lambda x: int(os.path.splitext(x)[0])\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except:\n",
    "            print(f\"Error loading {img_name}, skipping...\")\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, img_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2ea939",
   "metadata": {},
   "source": [
    "# 2. Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de08dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a091942",
   "metadata": {},
   "source": [
    "# 3. Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c262f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes=200):\n",
    "    #model = models.efficientnet_b4(pretrained=True)\n",
    "    weights = EfficientNet_B4_Weights.DEFAULT\n",
    "    model = models.efficientnet_b4(weights=weights)\n",
    "\n",
    "    \n",
    "    # Freeze base layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    # Replace classifier\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(num_ftrs, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, num_classes)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8cee59",
   "metadata": {},
   "source": [
    "# 4. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6dc67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    # Initialize\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = create_model().to(device)\n",
    "    \n",
    "    # Data Loaders\n",
    "    train_dataset = ImageFolder(root='../data/train', transform=train_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    \n",
    "    # Test Loader\n",
    "    test_dataset = TestDataset(root_dir='../data/test', transform=test_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # Training Setup\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "    \n",
    "    # Training Loop\n",
    "    for epoch in range(1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        print(f\"Epoch {epoch+1} Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1a41cd",
   "metadata": {},
   "source": [
    "# 5. Submission Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff87bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    filenames = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, names in tqdm(test_loader, desc=\"Generating Predictions\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            filenames.extend(names)\n",
    "    \n",
    "    # Create mapping\n",
    "    class_to_idx = ImageFolder(root='data/train').class_to_idx\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "    \n",
    "    # Create DataFrame\n",
    "    \"\"\"df = pd.DataFrame({\n",
    "        'ID': filenames,\n",
    "        'label': [idx_to_class[p] for p in predictions]\n",
    "    })\n",
    "    \n",
    "    # Sort numerically\n",
    "    df['num'] = df['ID'].apply(lambda x: int(os.path.splitext(x)[0]))\n",
    "    df = df.sort_values('num').drop('num', axis=1)\n",
    "    df.to_csv('../submission.csv', index=False)\"\"\"\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ID': filenames,\n",
    "    'label': [idx_to_class[p] for p in predictions]\n",
    "})\n",
    "\n",
    "# Extract numeric part from filenames like \"image1.jpg\"\n",
    "df['num'] = df['ID'].apply(lambda x: int(re.findall(r'\\d+', x)[0]))\n",
    "df = df.sort_values('num').drop('num', axis=1)\n",
    "df.to_csv('../src/data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef4240d",
   "metadata": {},
   "source": [
    "# Main Execution of data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1f53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    trained_model = train_model()\n",
    "    test_loader = DataLoader(\n",
    "        TestDataset(root_dir='../data/test', transform=test_transform),\n",
    "        batch_size=32, shuffle=False, num_workers=4\n",
    "    )\n",
    "    generate_submission(trained_model, test_loader, \n",
    "                       device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8d4bb6",
   "metadata": {},
   "source": [
    "# Activation functions and their derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ed16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # z = np.clip(z, -500, 500)\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def deriv_sigmoid(Z):\n",
    "    # print(Z.min(), Z.max())\n",
    "    return Z*(1-Z)\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def relu_derivative(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def softmax(Z):\n",
    "    expZ = np.exp(Z - np.max(Z, axis=0, keepdims=True))  # for stability\n",
    "    return expZ / np.sum(expZ, axis=0, keepdims=True)\n",
    "\n",
    "def compute_loss(AL, Y):\n",
    "    \"\"\"\n",
    "    Cross-entropy loss\n",
    "    AL: predictions (softmax output), shape (200, m)\n",
    "    Y: true labels (one-hot), shape (200, m)\n",
    "    \"\"\"\n",
    "    m = Y.shape[1]\n",
    "    loss = -np.sum(Y * np.log(AL + 1e-9)) / m\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb323f56",
   "metadata": {},
   "source": [
    "# Read from csv file or data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30690e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bird_dataset(csv_path):\n",
    "    df = pd.read_csv(csv_path, header=None)\n",
    "    y = df.iloc[:, 0].values\n",
    "    pixel_data = df.iloc[:, 1:].values\n",
    "    num_samples = pixel_data.shape[0]\n",
    "    image_size = 224\n",
    "    channel_size = image_size * image_size\n",
    "\n",
    "    R = pixel_data[:, :channel_size].reshape(num_samples, image_size, image_size)\n",
    "    G = pixel_data[:, channel_size:2*channel_size].reshape(num_samples, image_size, image_size)\n",
    "    B = pixel_data[:, 2*channel_size:].reshape(num_samples, image_size, image_size)\n",
    "\n",
    "    X = np.stack([R, G, B], axis=-1)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6aeab1",
   "metadata": {},
   "source": [
    "# Neurons in layers stored in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3787d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_sizes(n, point1, point2):\n",
    "    \"\"\"\n",
    "    Returns the list of layer sizes (input + hidden + output)\n",
    "    point1 and point2 are (layer_index, neuron_count) pairs\n",
    "    \"\"\"\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    slope = (y2 - y1) / (x2 - x1)\n",
    "    intercept = y1 - slope * x1\n",
    "    \n",
    "    layer_sizes = []\n",
    "    for i in range(n + 1):  # Including input and output layer\n",
    "        neurons = int(round(slope * i + intercept))\n",
    "        layer_sizes.append(neurons)\n",
    "    return layer_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6ce612",
   "metadata": {},
   "source": [
    "# Init Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa35997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(n, point1, point2, seed=42):\n",
    "    \"\"\"\n",
    "    Initializes weights and biases using the layer sizes.\n",
    "    Returns a dictionary of parameters.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    layer_sizes = get_layer_sizes(n, point1, point2)\n",
    "    parameters = {}\n",
    "\n",
    "    for l in range(1, len(layer_sizes)):\n",
    "        parameters[f\"W{l}\"] = np.random.randn(layer_sizes[l], layer_sizes[l-1]) * np.sqrt(2. / layer_sizes[l-1])\n",
    "        parameters[f\"b{l}\"] = np.zeros((layer_sizes[l], 1))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d7bf1d",
   "metadata": {},
   "source": [
    "# Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(x, parameters):\n",
    "    \"\"\"\n",
    "    x: input column vector of shape (150528, 1)\n",
    "    parameters: dictionary of W and b\n",
    "    Returns final output (softmax probabilities) and cache of intermediate values.\n",
    "    \"\"\"\n",
    "    A = x\n",
    "    cache = {\"A0\": x}\n",
    "    L = len(parameters) // 2  # number of layers\n",
    "\n",
    "    for l in range(1, L):\n",
    "        Z = parameters[f\"W{l}\"] @ A + parameters[f\"b{l}\"]\n",
    "        A = relu(Z)\n",
    "        cache[f\"Z{l}\"] = Z\n",
    "        cache[f\"A{l}\"] = A\n",
    "\n",
    "    # Output layer (softmax)\n",
    "    ZL = parameters[f\"W{L}\"] @ A + parameters[f\"b{L}\"]\n",
    "    AL = softmax(ZL)\n",
    "    cache[f\"Z{L}\"] = ZL\n",
    "    cache[f\"A{L}\"] = AL\n",
    "\n",
    "    return AL, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43896735",
   "metadata": {},
   "source": [
    "# Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40001c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    \"\"\"\n",
    "    Returns gradients dW, db for each layer\n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    m = X.shape[1]\n",
    "    L = len(parameters) // 2  # number of layers\n",
    "\n",
    "    # Output layer gradient\n",
    "    AL = cache[f\"A{L}\"]\n",
    "    dZL = AL - Y\n",
    "    grads[f\"dW{L}\"] = (1 / m) * dZL @ cache[f\"A{L-1}\"].T\n",
    "    grads[f\"db{L}\"] = (1 / m) * np.sum(dZL, axis=1, keepdims=True)\n",
    "\n",
    "    dA_prev = parameters[f\"W{L}\"].T @ dZL\n",
    "\n",
    "    # Hidden layers\n",
    "    for l in reversed(range(1, L)):\n",
    "        dZ = dA_prev * relu_derivative(cache[f\"Z{l}\"])\n",
    "        grads[f\"dW{l}\"] = (1 / m) * dZ @ cache[f\"A{l-1}\"].T\n",
    "        grads[f\"db{l}\"] = (1 / m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "        if l > 1:\n",
    "            dA_prev = parameters[f\"W{l}\"].T @ dZ\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5933d827",
   "metadata": {},
   "source": [
    "# Update Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fa381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2\n",
    "    for l in range(1, L + 1):\n",
    "        parameters[f\"W{l}\"] -= learning_rate * grads[f\"dW{l}\"]\n",
    "        parameters[f\"b{l}\"] -= learning_rate * grads[f\"db{l}\"]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517b7b0d",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6d864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, Y, n, point1, point2, epochs=100, learning_rate=0.01, print_loss=True):\n",
    "    \"\"\"\n",
    "    X: input data (150528, m)\n",
    "    Y: one-hot labels (200, m)\n",
    "    \"\"\"\n",
    "    parameters = init_parameters(n, point1, point2)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Forward Propagation\n",
    "        AL, cache = forward_propagation(X, parameters)\n",
    "\n",
    "        # Loss\n",
    "        loss = compute_loss(AL, Y)\n",
    "\n",
    "        # Backward Propagation\n",
    "        grads = backward_propagation(parameters, cache, X, Y)\n",
    "\n",
    "        # Update Parameters\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "\n",
    "        if print_loss and epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28d0e70",
   "metadata": {},
   "source": [
    "# Testing and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5806059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, parameters):\n",
    "    \"\"\"\n",
    "    X: input image(s), shape (150528, m)\n",
    "    Returns: predictions, shape (m,)\n",
    "    \"\"\"\n",
    "    AL, _ = forward_propagation(X, parameters)\n",
    "    predictions = np.argmax(AL, axis=0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a52ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(index, X, Y, parameters):\n",
    "    \"\"\"\n",
    "    index: index of the image in dataset\n",
    "    X: shape (150528, m)\n",
    "    Y: shape (200, m) — one-hot labels\n",
    "    parameters: learned parameters\n",
    "    \"\"\"\n",
    "    current_image = X[:, index:index+1]  # shape (150528, 1)\n",
    "    prediction = make_predictions(current_image, parameters)[0]\n",
    "    label = np.argmax(Y[:, index])\n",
    "\n",
    "    print(\"Prediction:\", prediction)\n",
    "    print(\"Label:\", label)\n",
    "    \n",
    "    img = current_image.reshape(224, 224, 3)\n",
    "    plt.imshow(img.astype(np.uint8))\n",
    "    plt.title(f\"Predicted: {prediction}, Label: {label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211773ed",
   "metadata": {},
   "source": [
    "# Accuracy vs no of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ce0f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, labels):\n",
    "    \"\"\"\n",
    "    predictions: shape (m,)\n",
    "    labels: shape (200, m) — one-hot\n",
    "    \"\"\"\n",
    "    true_labels = np.argmax(labels, axis=0)\n",
    "    return np.mean(predictions == true_labels)\n",
    "\n",
    "def plot_accuracy_vs_layers(X, Y, layer_range, point1, point2, epochs=50, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    X: input data (150528, m)\n",
    "    Y: one-hot labels (200, m)\n",
    "    layer_range: list or range of layer counts to try (e.g., range(2, 9))\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "\n",
    "    for n_layers in layer_range:\n",
    "        print(f\"Training with {n_layers} layers...\")\n",
    "        parameters = train_model(X, Y, n_layers, point1, point2, epochs=epochs, learning_rate=learning_rate, print_loss=False)\n",
    "        preds = make_predictions(X, parameters)\n",
    "        acc = compute_accuracy(preds, Y)\n",
    "        print(f\"Accuracy for {n_layers} layers: {acc:.4f}\")\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(list(layer_range), accuracies, marker='o')\n",
    "    plt.title(\"Accuracy vs Number of Layers\")\n",
    "    plt.xlabel(\"Number of Layers\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4401e455",
   "metadata": {},
   "source": [
    "# Main function for final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b41089f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
